{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import morfeusz2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator as op\n",
    "import itertools as it\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korpus dokumentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Potter i Czara Ognia.txt',\n",
       " 'Harry Potter i Insygnia Smierci.txt',\n",
       " 'Harry Potter i Kamien Filozoficzny.txt',\n",
       " 'Harry Potter i Komnata Tajemnic.txt',\n",
       " 'Harry Potter i Ksiaze Polkrwi.txt',\n",
       " 'Harry Potter i Przeklete Dziecko.txt',\n",
       " 'Harry Potter i Wiezien Azkabanu.txt',\n",
       " 'Harry Potter i Zakon Feniksa.txt',\n",
       " 'Opowiesci z Narni. Kon i jego chlopiec.txt',\n",
       " 'Opowiesci z Narni. Ksiaze Kaspian.txt',\n",
       " 'Opowiesci z Narni. Lew, czarownica i stara szafa.txt',\n",
       " 'Opowiesci z Narni. Ostatnia bitwa.txt',\n",
       " 'Opowiesci z Narni. Podroz Wedrowca do Switu.txt',\n",
       " 'Opowiesci z Narni. Siostrzeniec Czarodzieja.txt',\n",
       " 'Opowiesci z Narni. Srebrne krzeslo.txt',\n",
       " 'Zmierzch.Ksiezyc w Nowiu.txt',\n",
       " 'Zmierzch.Przed Switem.txt',\n",
       " 'Zmierzch.Zacmienie.txt',\n",
       " 'Zmierzch.Zmierzch.txt',\n",
       " 'Zmierzch.Zycie i Smierc.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dir = './literatura - original'\n",
    "corpus = PlaintextCorpusReader(corpus_dir, \".*\\.txt\")\n",
    "files_names = corpus.fileids()\n",
    "files_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wstepne przygotowanie dokumentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "for file in files_names:\n",
    "    documents[file] = corpus.raw(file)\n",
    "print(json.dumps(documents, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist_file = open(\"./stopwords_pl.txt\", \"r\", encoding=\"UTF-8\")\n",
    "stoplist = stoplist_file.read().splitlines()\n",
    "stoplist_file.close()\n",
    "stoplist = stoplist[4:]\n",
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    morf = morfeusz2.Morfeusz()\n",
    "    segments = it.groupby(morf.analyse(text), op.itemgetter(0,1))\n",
    "    def disambiguate(group):\n",
    "        pairs = ((len(descr), lemma) for _, _, (_, lemma, descr, _, _, ) in group)\n",
    "        perpl, lemma = min(pairs)\n",
    "        return lemma.split(\":\")\n",
    "    lemmas = (disambiguate(group) for key, group in segments)\n",
    "    return \" \".join(filter(str.isalpha, lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in documents:\n",
    "    documents[key] = documents[key].lower()\n",
    "    documents[key] = \"\".join([char for char in documents[key] if char not in string.punctuation])\n",
    "    documents[key] = lemmatize(documents[key])\n",
    "    documents[key] = \" \".join([word for word in word_tokenize(documents[key]) if word not in stoplist])\n",
    "\n",
    "print(json.dumps(documents, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morf = morfeusz2.Morfeusz()\n",
    "morf.analyse(\"Ala ma kota\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utworzenie macierzy częstości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame.from_dict(documents, orient=\"index\")\n",
    "docs.columns = ['content']\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(20, 7469))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "counts_tf = count_vectorizer.fit_transform(docs['content'])\n",
    "counts_tf.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01355401, 0.01708829, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], shape=(20, 7469))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "counts_tfidf = tfidf_vectorizer.fit_transform(docs['content'])\n",
    "counts_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Katalogi na wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./wordclouds\"):\n",
    "    os.mkdir(\"./wordclouds\")\n",
    "if not os.path.exists(\"./topics\"):\n",
    "    os.mkdir(\"./topics\")\n",
    "if not os.path.exists(\"./clusters\"):\n",
    "    os.mkdir(\"./clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chumry tagów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color= \"white\",\n",
    "    max_words = 5000,\n",
    "    contour_width=3,\n",
    "    contour_color=\"steelblue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, row in docs.iterrows():\n",
    "    wordcloud.generate(row['content'])\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(index.replace(\".txt\", \"\"))\n",
    "    plt.savefig(f\"./wordclouds/{index}_wordcloud.png\")\n",
    "    plt.clf() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8adddbb134789cb44433880ed4e24bc2bf07066665b89b9f3523b7521a6a125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
